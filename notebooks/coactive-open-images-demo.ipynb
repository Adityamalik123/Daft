{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c813429",
   "metadata": {},
   "source": [
    "# Daft Demo\n",
    "\n",
    "## Here we show a demo of Daft of the following: \n",
    "- Initializing our cluster\n",
    "- Daft Data Repos\n",
    "- Use a Python Dataclass to define a Schema\n",
    "- Load existing data from our Data Repos\n",
    "- Write a function to download data from the web\n",
    "- Write a function to decode and resize the image\n",
    "- Write our own Schema for image storage\n",
    "- Save downloaded images to the cloud\n",
    "- Write our own embedding extractor for batch inference\n",
    "- Save our embeddings to a data repo\n",
    "- Preview our Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaf4290",
   "metadata": {},
   "source": [
    "## Initializing our cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdff99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import daft\n",
    "\n",
    "daft.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9efc9b",
   "metadata": {},
   "source": [
    "## Daft Data Repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e501a70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from daft import Datarepo\n",
    "\n",
    "Datarepo.list_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b598a",
   "metadata": {},
   "source": [
    "## Defining our Own Schema\n",
    "- ORM for binary data\n",
    "- Translates to parquet under the hood\n",
    "- Support for logical types like images, numpy arrays and any other types that you can define yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca769a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from daft import dataclass\n",
    "\n",
    "@dataclass\n",
    "class OpenImagesMetadata:\n",
    "    url: str\n",
    "    size: int\n",
    "    id: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e133283",
   "metadata": {},
   "source": [
    "## Reading Data from our Data Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78703eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "readback = Datarepo.from_id('openimages-dc-8000-v2', data_type=OpenImagesMetadata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde50161",
   "metadata": {},
   "source": [
    "## Previewing our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99920d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(readback)\n",
    "readback.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94297d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a5c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ImageBinaryPayload:\n",
    "    url: str\n",
    "    data: bytes = dataclasses.field(repr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402cf147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c4ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import requests\n",
    "from typing import List\n",
    "\n",
    "def download_single(image_metadata: OpenImagesMetadata) -> ImageBinaryPayload:\n",
    "    r = requests.get(image_metadata.url)\n",
    "    if r.status_code == 200:\n",
    "        return ImageBinaryPayload(image_metadata.url, r.content)\n",
    "    else:\n",
    "        return ImageBinaryPayload(image_metadata.url, b'')\n",
    "\n",
    "\n",
    "def download_batch(batch: List[OpenImagesMetadata]) -> List[ImageBinaryPayload]:\n",
    "    with concurrent.futures.ThreadPoolExecutor() as exector : \n",
    "        futures = exector.map(download_single, batch)\n",
    "        return list(futures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4dccb7",
   "metadata": {},
   "source": [
    "### Download via a non-batched map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae6d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "image_payload_single = readback.map(download_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1853fe",
   "metadata": {},
   "source": [
    "### Download via a batched map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feecc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "image_payload_batch = readback.map_batches(download_batch, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfc076a",
   "metadata": {},
   "source": [
    "## Decode and Resize our downloaded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9fcb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import PIL.Image\n",
    "from daft.fields import DaftImageField\n",
    "from daft.types import DaftImageType\n",
    "\n",
    "@dataclass\n",
    "class ProcessedImageData:\n",
    "    url: str\n",
    "    img: PIL.Image.Image = DaftImageField(encoding=DaftImageType.Encoding.JPEG)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_image_payload(cls, payload: ImageBinaryPayload, size:int=256) -> 'ProcessedImageData':\n",
    "        with io.BytesIO(payload.data) as f:\n",
    "            try:\n",
    "                img = PIL.Image.open(f)\n",
    "                img = img.resize((size,size))\n",
    "                img = img.convert(\"RGB\")\n",
    "            except Exception as e:\n",
    "                img = PIL.Image.new(\"RGB\", (size, size))\n",
    "            return cls(payload.url, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a5e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_decoded_images = image_payload_batch.map(ProcessedImageData.from_image_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8b66b9",
   "metadata": {},
   "source": [
    "### Lets look at our images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a726e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_decoded_images.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcfeb14",
   "metadata": {},
   "source": [
    "### Defining our Embedding data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afdbaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@dataclass\n",
    "class ProcessedEmbedding:\n",
    "    url: str\n",
    "    model: str\n",
    "    dim: int\n",
    "    mean: float\n",
    "    std: float\n",
    "    embedding: np.ndarray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517e1806",
   "metadata": {},
   "source": [
    "### Defining our function for Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ca0ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "        \n",
    "class BatchInferModel:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Here we init our model as well as needed data transforms\n",
    "        \"\"\"\n",
    "        self.model_name = \"resnet18\"\n",
    "        model = torchvision.models.resnet18(pretrained=True).eval()\n",
    "        self.feature_extractor = torchvision.models.feature_extraction.create_feature_extractor(\n",
    "            model=model, \n",
    "            return_nodes={'avgpool': 'embedding'}\n",
    "        )\n",
    "        self.to_tensor = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            )]\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def prepare_batch(self, image_data: List[ProcessedImageData]) -> Tuple[torch.Tensor, List[str]]:\n",
    "        \"\"\"\n",
    "        Here we convert our PIL image to a normalized tensor\n",
    "        \"\"\"\n",
    "        pil_images = [item.img for item in image_data]\n",
    "        urls = [item.url for item in image_data]\n",
    "        return torch.stack([self.to_tensor(img) for img in pil_images]), urls\n",
    "    \n",
    "    def __call__(self, image_data: List[ProcessedImageData]) -> List[ProcessedEmbedding]:\n",
    "        \"\"\"\n",
    "        Here we extract our embedding with resnet 18\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            tensor, urls = self.prepare_batch(image_data)\n",
    "            embedding =  self.feature_extractor(tensor.float())['embedding'].view(len(image_data), -1)\n",
    "            np_embedding = embedding.cpu().numpy()\n",
    "            dim = np_embedding.shape[1]\n",
    "            per_image_embedding = np.vsplit(np_embedding, np.arange(1, len(image_data)))\n",
    "                        \n",
    "            return [ProcessedEmbedding(\n",
    "                url=url,\n",
    "                embedding=e,\n",
    "                mean=e.mean(),\n",
    "                std=e.std(),\n",
    "                model=self.model_name,\n",
    "                dim=dim)\n",
    "                   for url, e in zip(urls, per_image_embedding)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7640d6e",
   "metadata": {},
   "source": [
    "## Running large scale batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c4c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "embeddings = resized_decoded_images.map_batches(BatchInferModel, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761e01a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7382f72f",
   "metadata": {},
   "source": [
    "## Save our extracted embeddings to the cloud in Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35ccb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.save('open-images-8k-processed-embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88a08f1",
   "metadata": {},
   "source": [
    "## Peeking under the Hood of Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9c362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ProcessedEmbedding._daft_schema.arrow_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f336a115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
